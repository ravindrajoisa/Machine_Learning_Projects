{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5585bfcf-2302-47e7-bf4d-7f8893e70425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read video from web camera using openCV\n",
    "# Face detection in video\n",
    "# Click 20 pics of the person who comed in the front of camera and dave them as numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99f107e0-1f3e-4b2f-ad42-d358fd98a8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the name of the person:  Aniketh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved so far10\n",
      "Saved so far21\n",
      "Saved so far32\n",
      "Saved so far43\n",
      "Saved so far54\n",
      "Saved so far65\n",
      "Saved so far76\n",
      "Saved so far87\n",
      "Saved so far98\n",
      "Saved so far109\n",
      "Saved so far120\n",
      "Saved so far131\n",
      "Saved so far142\n",
      "Saved so far153\n",
      "Saved so far164\n",
      "(169, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# create a camera object\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "# Ask the name\n",
    "fileName = input(\"Enter the name of the person: \")\n",
    "dataset_path = \"./data/\"\n",
    "skip = 0\n",
    "offset = 20\n",
    "\n",
    "# Model\n",
    "model = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "\n",
    "# creating a list to save face data\n",
    "faceData = []\n",
    "cnt = 0\n",
    "\n",
    "# Read image from camera object\n",
    "while True:\n",
    "    success, img = cam.read()\n",
    "    if not success:\n",
    "        print(\"Reading Camera Failed!\")\n",
    "\n",
    "    # Store the gray image\n",
    "    grayImg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = model.detectMultiScale(img,1.3,5)\n",
    "\n",
    "    # pick and sorting the face with largest bounding box\n",
    "    faces = sorted(faces, key=lambda f:f[2]*f[3])\n",
    "    # pick the largest face\n",
    "    if len(faces)>0:\n",
    "        f = faces[-1]\n",
    "        x,y,w,h = f\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h), (0,255,0),2)\n",
    "\n",
    "    # crop and save the largest face\n",
    "        cropped_face = img[y - offset:y+h + offset, x - offset:x + offset+w]\n",
    "        cropped_face = cv2.resize(cropped_face, (100, 100))\n",
    "        skip += 1\n",
    "        if skip%10 == 0:\n",
    "            faceData.append(cropped_face)\n",
    "            print(\"Saved so far\" + str(len(faceData)))\n",
    "        \n",
    "        faceData.append(cropped_face)\n",
    "    \n",
    "    cv2.imshow(\"Image Window\", img)\n",
    "#    cv2.imshow(\"Cropped Face\", cropped_face)\n",
    "    \n",
    "    key = cv2.waitKey(1)  # pause here for 1 ms before you read the next image\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# write the faceData on the disk\n",
    "faceData = np.asarray(faceData)\n",
    "print(faceData.shape)\n",
    "\n",
    "# release camera and destroy window\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba04cd7c-5d44-4489-ba84-75ec4939e38e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
